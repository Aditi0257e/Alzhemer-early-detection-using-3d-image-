# -*- coding: utf-8 -*-
"""ALZHEIMER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ykj9y2k2MUYhqLdKlysGtg2ZXdXuspj4
"""

# Install required packages
!pip install -q opencv-python
!pip install -q matplotlib

# Import libraries
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

import zipfile
import os

# Define path to the uploaded zip file and extraction directory
zip_path = '/content/archive.zip'
extract_path = '/content/dataset'

# Create extraction directory if it doesn't exist
os.makedirs(extract_path, exist_ok=True)

# Unzip the file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("✅ Dataset extracted successfully to:", extract_path)

import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split

data_dir = '/content/dataset'  # this should match your unzipped folder path
image_size = 224  # Resize all images to 224x224
X = []
y = []
labels_dict = {}

#import imghdr  # to check for valid image types

valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')

for i, label in enumerate(sorted(os.listdir(data_dir))):
    labels_dict[label] = i
    folder_path = os.path.join(data_dir, label)
    for root, dirs, files in os.walk(folder_path):
        for img_name in files:
            if not img_name.lower().endswith(valid_extensions):
                print(f"Skipped non-image file: {img_name}")
                continue
            img_path = os.path.join(root, img_name)
            try:
                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                if img is None or img.size == 0:
                    print(f"Skipped unreadable image: {img_path}")
                    continue
                img = cv2.resize(img, (image_size, image_size))
                X.append(img)
                y.append(i)
            except Exception as e:
                print(f"Failed to process image {img_path}: {e}")

print("✅ Total valid images loaded:", len(X))
print("✅ Corresponding labels:", len(y))

import os

data_dir = "/content/dataset/Data"

class_names = ["Non Demented", "Very mild Dementia", "Mild Dementia", "Moderate Dementia"]

import cv2
import numpy as np

max_images = 5000  # Limit for memory
count = 0

X = []
y = []

for i, label in enumerate(class_names):
    folder = os.path.join(data_dir, label)
    for img_name in os.listdir(folder):
        if count >= max_images:
            break
        img_path = os.path.join(folder, img_name)
        try:
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None or img.size == 0:
                continue
            img = cv2.resize(img, (100, 100))
            X.append(img)
            y.append(i)
            count += 1
        except:
            continue

print("✅ Loaded limited number of images:", len(X))

pip install torch torchvision

import torch
import torch.nn as nn
import torchvision.models as models

# CBAM components
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)

        self.fc = nn.Sequential(
            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),
            nn.ReLU(),
            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        return self.sigmoid(avg_out + max_out)

class SpatialAttention(nn.Module):
    def __init__(self):
        super(SpatialAttention, self).__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        return self.sigmoid(self.conv(x))

class CBAM(nn.Module):
    def __init__(self, channels, ratio=16):
        super(CBAM, self).__init__()
        self.ca = ChannelAttention(channels, ratio)
        self.sa = SpatialAttention()

    def forward(self, x):
        x = x * self.ca(x)
        x = x * self.sa(x)
        return x

class ResNetCBAM(nn.Module):
    def __init__(self, num_classes=4):
        super(ResNetCBAM, self).__init__()
        self.base_model = models.resnet18(pretrained=True)
        self.cbam1 = CBAM(64)
        self.cbam2 = CBAM(128)
        self.cbam3 = CBAM(256)
        self.cbam4 = CBAM(512)

        # Hook CBAMs after layer blocks
        self.base_model.layer1[0].cbam = self.cbam1
        self.base_model.layer2[0].cbam = self.cbam2
        self.base_model.layer3[0].cbam = self.cbam3
        self.base_model.layer4[0].cbam = self.cbam4

        # Replace final layer
        in_features = self.base_model.fc.in_features
        self.base_model.fc = nn.Linear(in_features, num_classes)

    def forward(self, x):
        x = self.base_model.conv1(x)
        x = self.base_model.bn1(x)
        x = self.base_model.relu(x)
        x = self.base_model.maxpool(x)

        x = self.base_model.layer1(x)
        x = self.base_model.layer1[0].cbam(x)

        x = self.base_model.layer2(x)
        x = self.base_model.layer2[0].cbam(x)

        x = self.base_model.layer3(x)
        x = self.base_model.layer3[0].cbam(x)

        x = self.base_model.layer4(x)
        x = self.base_model.layer4[0].cbam(x)

        x = self.base_model.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.base_model.fc(x)
        return x

import torch.optim as optim

# Initialize model, loss, and optimizer
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = ResNetCBAM(num_classes=4).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

import os

os.listdir("/content/dataset")

import shutil
from sklearn.model_selection import train_test_split
from pathlib import Path

src_root = Path('/content/dataset/Data')
train_root = Path('/content/dataset/train')
val_root = Path('/content/dataset/val')

# Create train/val folders
for subfolder in os.listdir(src_root):
    full_path = src_root / subfolder
    if full_path.is_dir():
        images = list(full_path.glob('*'))
        train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42)

        (train_root / subfolder).mkdir(parents=True, exist_ok=True)
        (val_root / subfolder).mkdir(parents=True, exist_ok=True)

        for img in train_imgs:
            shutil.copy(img, train_root / subfolder / img.name)
        for img in val_imgs:
            shutil.copy(img, val_root / subfolder / img.name)

import torchvision.transforms as transforms
from torchvision import datasets
from torch.utils.data import DataLoader

# Grayscale transforms
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])  # For grayscale: 1 channel mean and std
])

# Load datasets
train_dataset = datasets.ImageFolder(root='/content/dataset/train', transform=transform)
val_dataset = datasets.ImageFolder(root='/content/dataset/val', transform=transform)

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)

print("✅ Grayscale data loaders ready")
print("Train classes:", train_dataset.classes)
print("Train size:", len(train_dataset), "| Validation size:", len(val_dataset))

from tqdm import tqdm
!pip install tqdm

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
from tqdm import tqdm

# Use GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load pre-trained ResNet18 model
model = models.resnet18(pretrained=True)

# Modify input conv layer to accept grayscale (1 channel) instead of RGB (3 channels)
model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)

# Change the final fully connected layer for the number of classes
num_classes = len(train_dataset.classes)
model.fc = nn.Linear(model.fc.in_features, num_classes)

model = model.to(device)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Number of epochs
num_epochs = 5

# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    loop = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}", ncols=100)
    for images, labels in loop:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        loop.set_postfix(loss=loss.item(), acc=100 * correct / total)

print("✅ Training complete")